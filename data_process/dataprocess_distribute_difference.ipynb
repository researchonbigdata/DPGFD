{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math, csv, gzip, os, io, copy, threading, re\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time as timee\n",
    "from contextlib import contextmanager\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from multiprocessing import Pipe, Pool\n",
    "from scipy import stats\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from features import time_gap2, time2, connector_duplicate2, area_change2, recall_rate2, energy_dispersion2, \\\n",
    "    mean_voc_time2, n_unique_persons2\n",
    "# %%\n",
    "import features as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = timee.time()\n",
    "    yield\n",
    "    print(f\"{title} - done in {timee.time()-t0}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(mx:np.ndarray):  # 归一化\n",
    "    shape=mx.shape\n",
    "    mx=mx.reshape((-1,shape[-1]))\n",
    "    for k in range(mx.shape[-1]):\n",
    "        mx[:,k]=(mx[:,k]-np.min(mx[:,k]))/(np.max(mx[:,k])-np.min(mx[:,k]))\n",
    "    mx=mx.reshape(shape)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读数据、数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '~/pythonprojs/sichuan/'\n",
    "all_user = pd.read_csv(data_path+'data/train_user.csv')\n",
    "train_voc = pd.read_csv(data_path + 'data/train.csv')\n",
    "test_voc = pd.read_csv(data_path + 'data/test.csv')\n",
    "train_voc['start_datetime'] = pd.to_datetime(train_voc['start_datetime']) # 转换时间类型\n",
    "test_voc['start_datetime'] = pd.to_datetime(test_voc['start_datetime']) # 转换时间类型\n",
    "train_voc['hour'] = train_voc['start_datetime'].dt.hour  # 提取小时属性\n",
    "test_voc['hour'] = test_voc['start_datetime'].dt.hour\n",
    "train_voc = train_voc.merge(all_user[['phone_no_m', 'label']], how='left', on='phone_no_m') # 测试集合通话记录加上\n",
    "test_voc = test_voc.merge(all_user[['phone_no_m', 'label']], how='left', on='phone_no_m')\n",
    "all_user.set_index(keys='phone_no_m', drop=False, inplace=True)\n",
    "train_voc=train_voc.set_index('phone_no_m',drop=False)\n",
    "test_voc=test_voc.set_index('phone_no_m',drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user = set(train_voc['phone_no_m'].tolist()) # train_user set\n",
    "test_user = set(test_voc['phone_no_m'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先计算一部分特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# calculate feature\n",
    "\n",
    "# train_voc['mean_dur'] = train_voc.groupby(['phone_no_m', pd.Grouper(key='start_datetime', freq='W')])[\n",
    "#     'call_dur'].transform(np.nanmean)  # 通话时长平均\n",
    "# train_voc['var_dur'] = train_voc.groupby(['phone_no_m', pd.Grouper(key='start_datetime', freq='W')])[\n",
    "#     'call_dur'].transform(np.nanvar)  # 通话时长方差\n",
    "train_voc['sum_call_times'] = train_voc.groupby(['phone_no_m'])['phone_no_m'].transform('count')  #\n",
    "train_voc['every_one_calltimes'] = train_voc.groupby(['phone_no_m', 'opposite_no_m'])['phone_no_m'].transform(\n",
    "    'count')\n",
    "train_voc['energy_dispersion'] = train_voc['every_one_calltimes'] / train_voc['sum_call_times']  # 精力分散度\n",
    "# 入度/出度\n",
    "train_voc['degree']=train_voc.groupby(['phone_no_m',pd.Grouper(key='start_datetime',freq='W'),'calltype_id'])['phone_no_m'].transform('count')\n",
    "#邻居度\n",
    "train_voc['neighbor_degree']=train_voc.groupby(['opposite_no_m',pd.Grouper(key='start_datetime',freq='W'),'calltype_id'])['phone_no_m'].transform('count')\n",
    "del train_voc['sum_call_times']\n",
    "del train_voc['every_one_calltimes']\n",
    "\n",
    "# test_voc['mean_dur'] = test_voc.groupby(['phone_no_m', pd.Grouper(key='start_datetime', freq='W')])[\n",
    "#     'call_dur'].transform(np.nanmean)  # 通话时长平均\n",
    "# test_voc['var_dur'] = test_voc.groupby(['phone_no_m', pd.Grouper(key='start_datetime', freq='W')])[\n",
    "#     'call_dur'].transform(np.nanvar)  # 通话时长方差\n",
    "test_voc['sum_call_times'] = test_voc.groupby(['phone_no_m'])['phone_no_m'].transform('count')  #\n",
    "test_voc['every_one_calltimes'] = test_voc.groupby(['phone_no_m', 'opposite_no_m'])['phone_no_m'].transform(\n",
    "    'count')\n",
    "test_voc['energy_dispersion'] = test_voc['every_one_calltimes'] / test_voc['sum_call_times']  # 精力分散度\n",
    "# 入度/出度\n",
    "test_voc['degree']=test_voc.groupby(['phone_no_m',pd.Grouper(key='start_datetime',freq='W'),'calltype_id'])['phone_no_m'].transform('count')\n",
    "#邻居度\n",
    "test_voc['neighbor_degree']=test_voc.groupby(['opposite_no_m',pd.Grouper(key='start_datetime',freq='W'),'calltype_id'])['phone_no_m'].transform('count')\n",
    "del test_voc['sum_call_times']\n",
    "del test_voc['every_one_calltimes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Vertex:\n",
    "    def __init__(self,key):\n",
    "        self.id=key\n",
    "        self.connect_to={}\n",
    "    def add_neighbor(self,nbr,weight):\n",
    "        self.connect_to[nbr]=weight\n",
    "    def __str__(self):\n",
    "        return str(self.id)\n",
    "    def getId(self):\n",
    "        return self.id\n",
    "    def getNeighbors(self):\n",
    "        return self.connect_to\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.verList=dict()\n",
    "        self.numVertices=0\n",
    "    def addVertex(self,key):\n",
    "        if key not in self.verList:\n",
    "            self.numVertices+=1\n",
    "            self.verList[key]=Vertex(key)\n",
    "    def addEdge(self,f,t,weight):\n",
    "        self.addVertex(f)\n",
    "        self.addVertex(t)\n",
    "        self.verList[f].add_neighbor(t,weight)\n",
    "        self.verList[t].add_neighbor(f,-weight)\n",
    "    def __iter__(self):\n",
    "        return iter(self.verList.values())\n",
    "    def indegree(self,vertex):\n",
    "        value=0\n",
    "        for neigh,weight in self.verList[vertex].getNeighbors().items():\n",
    "            if weight==-1:value+=1\n",
    "        return value\n",
    "    def outdegree(self,vertex):\n",
    "        value=0\n",
    "        for neigh,weight in self.verList[vertex].getNeighbors().items():\n",
    "            if weight==1:value+=1\n",
    "        return value\n",
    "    def getCE(self,node):\n",
    "        common_neigh=0\n",
    "        for neighbor in self.verList[node].getNeighbors():\n",
    "            for neighbor2 in self.verList[neighbor].getNeighbors():\n",
    "                if neighbor2 in self.verList[node].getNeighbors():common_neigh+=1\n",
    "        return common_neigh\n",
    "    def getNeighbor(self,node):\n",
    "        return self.verList[node].getNeighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_vocs = [g for _, g in train_voc.groupby(pd.Grouper(key='start_datetime', freq='W'))]\n",
    "test_vocs = [g for _, g in test_voc.groupby(pd.Grouper(key='start_datetime', freq='W'))]\n",
    "\n",
    "train_nets = [Graph() for i in range(len(train_vocs))]  # 训练集网络\n",
    "test_nets = [Graph() for i in range(len(test_vocs))]  # 测试集网络\n",
    "train_neighbor = {}  # neighbor of training set\n",
    "test_neighbor = {}\n",
    "\n",
    "for idx, net in enumerate(train_nets):  # 每个时间片构一个图\n",
    "    for node in train_user:\n",
    "        net.addVertex(node)\n",
    "    voc = train_vocs[idx]\n",
    "    for row in voc.itertuples():  # 每次通话\n",
    "        calltype_id = getattr(row, 'calltype_id')\n",
    "        source = getattr(row, 'phone_no_m')\n",
    "        target = getattr(row, 'opposite_no_m')\n",
    "        if calltype_id==1:\n",
    "            net.addEdge(source,target,1)\n",
    "            \n",
    "        elif calltype_id==2:\n",
    "            net.addEdge(source,target,-1)\n",
    "            # net.addEdge(target,source,1)\n",
    "        if source not in train_neighbor: train_neighbor[source] = []\n",
    "        train_neighbor[source].append(target)\n",
    "\n",
    "for idx, net in enumerate(test_nets):  # 每个时间片的图\n",
    "    for node in test_user:\n",
    "        net.addVertex(node)\n",
    "    voc = test_vocs[idx]\n",
    "    for row in voc.itertuples():  # 每次通话\n",
    "        calltype_id = getattr(row, 'calltype_id')\n",
    "        source = getattr(row, 'phone_no_m')\n",
    "        target = getattr(row, 'opposite_no_m')\n",
    "#         net.add_edge(source, target) if calltype_id == 1 else net.add_edge(target, source)\n",
    "        if calltype_id==1:\n",
    "            net.addEdge(source,target,1)\n",
    "            net.addEdge(target,source,-1)\n",
    "        elif calltype_id==2:\n",
    "            net.addEdge(source,target,-1)\n",
    "            net.addEdge(target,source,1)\n",
    "        if source not in test_neighbor: test_neighbor[source] = []\n",
    "        test_neighbor[source].append(target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算图特征和其余的动态特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         ... 0.         0.         0.02917385]\n",
      "train feature  - done in 434.8685438632965s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82584\\AppData\\Local\\Temp\\ipykernel_16964\\2283971256.py:87: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np_feature = np.array(np_feature).astype(np.float)\n",
      "C:\\Users\\82584\\AppData\\Local\\Temp\\ipykernel_16964\\2283971256.py:88: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np_id_feature = np.array(np_id_feature).astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "tmp_train_user = train_user.copy()\n",
    "tmp_test_user = test_user.copy()\n",
    "\n",
    "train_slice_feature = dict()\n",
    "test_slice_feature = dict()\n",
    "\n",
    "train_id_feature = dict()\n",
    "test_id_feature = dict()\n",
    "\n",
    "each_feature_costtime=[]\n",
    "\n",
    "with timer('train feature '):\n",
    "    # 计算动态特征\n",
    "    for idx, slice in enumerate(train_vocs):  \n",
    "        ps = [g for _, g in slice.groupby('phone_no_m')]\n",
    "        net = train_nets[idx]\n",
    "        \n",
    "        for p in ps:  # each person in this slice\n",
    "            p_dict=p.to_dict(orient='list')\n",
    "            id = p['phone_no_m'].iloc[0]\n",
    "            # 联系人重复率\n",
    "            t0=timee.time()\n",
    "            if idx == 0:\n",
    "                repeat_rate = 0\n",
    "            else:\n",
    "                pre_week = train_vocs[idx - 1]\n",
    "                pre_week = pre_week.loc[pre_week['phone_no_m'] == id]\n",
    "                repeat_rate = connector_duplicate2(pre_week.to_dict(orient='list'), p_dict)\n",
    "            t1=timee.time()\n",
    "            if idx==0:each_feature_costtime.append(t1-t0)\n",
    "            # 入度\n",
    "            indegree = net.indegree(id)\n",
    "            t2=timee.time()\n",
    "            if idx==0:each_feature_costtime.append(t2-t1)\n",
    "            # 出度\n",
    "            outdegree = net.outdegree(id)\n",
    "            t3=timee.time()\n",
    "            if idx==0:each_feature_costtime.append(t3-t2)\n",
    "            # 邻居平均度\n",
    "            neighbor_degree = list()\n",
    "            for neigh in net.getNeighbor(id):\n",
    "                neighbor_degree.append(net.indegree(neigh)+net.outdegree(neigh))\n",
    "            neighbor_degree = np.mean(neighbor_degree)\n",
    "            t4=timee.time()\n",
    "            if idx==0:each_feature_costtime.append(t4-t3)\n",
    "            # 聚类系数\n",
    "            coefficient = net.getCE(id)\n",
    "            t5=timee.time()\n",
    "            if idx==0:each_feature_costtime.append(t5-t4)\n",
    "            # 回拨率\n",
    "            recall_rate = features.recall_rate2(p_dict)\n",
    "            t6=timee.time()\n",
    "            if idx==0:each_feature_costtime.append(t6-t5)\n",
    "            # 通话时间分布\n",
    "            time_dis = [0 for i in range(24)]\n",
    "            for time, count in p['hour'].value_counts(normalize=True).to_dict().items():\n",
    "                time_dis[time] = count\n",
    "            t7=timee.time()\n",
    "            if idx==0:each_feature_costtime.append(t7-t6)\n",
    "            # 平均通话时长\n",
    "            mean_dur = p['mean_dur'].iloc[0]\n",
    "            # 通话时长方差\n",
    "            var_dur = p['var_dur'].iloc[0]\n",
    "            if idx == 0: train_slice_feature[id] = list()\n",
    "            train_slice_feature[id].append([indegree, outdegree, neighbor_degree, coefficient, recall_rate, repeat_rate, mean_dur,var_dur] + time_dis)\n",
    "            tmp_train_user.discard(id)\n",
    "        for id in list(tmp_train_user):  # persons not in this slice\n",
    "            if idx == 0: train_slice_feature[id] = list()\n",
    "            train_slice_feature[id] .append( [0 for i in range(32)])\n",
    "        tmp_train_user=train_user.copy()\n",
    "    print(np.array(each_feature_costtime)*len(train_vocs))\n",
    "    # 计算身份特征\n",
    "    static_voc = train_voc[['phone_no_m', 'energy_dispersion']].drop_duplicates(subset='phone_no_m').set_index(\n",
    "        keys='phone_no_m')\n",
    "    for id in list(train_user):\n",
    "        idcard_cnt = all_user.loc[id, 'idcard_cnt']\n",
    "        ed = static_voc.loc[id, 'energy_dispersion']\n",
    "        train_id_feature[id] = [idcard_cnt, ed]\n",
    "np_feature=[]   \n",
    "np_id_feature=[]\n",
    "labels=[]\n",
    "for id, v in train_slice_feature.items(): \n",
    "    np_feature.append(v)\n",
    "    np_id_feature.append(train_id_feature[id])\n",
    "    labels.append(all_user.loc[id, 'label'])\n",
    "\n",
    "np_feature = np.array(np_feature).astype(np.float)\n",
    "np_id_feature = np.array(np_id_feature).astype(np.float)\n",
    "labels = np.array(labels)\n",
    "# train_n=int(len(np_feature)/4)*3\n",
    "np_feature[:, :,[0,1, 2, 3, 6,7]] = normalize(np_feature[:, :,[0,1, 2, 3, 6, 7]])\n",
    "\n",
    "np_id_feature[:,[0]]=normalize(np_id_feature[:,[0]])\n",
    "\n",
    "np.save(arr=np_feature, file=data_path + f'data_after/mymodel/train_x.npy')\n",
    "np.save(arr=np_id_feature, file=data_path + 'data_after/mymodel/train_x_id.npy')\n",
    "np.save(arr=labels, file=data_path + f'data_after/mymodel/train_y.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\software\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test feature  - done in 112.36120414733887s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82584\\AppData\\Local\\Temp\\ipykernel_16964\\4109290276.py:52: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np_feature = np.array(np_feature).astype(np.float)\n",
      "C:\\Users\\82584\\AppData\\Local\\Temp\\ipykernel_16964\\4109290276.py:53: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np_id_feature = np.array(np_id_feature).astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "with timer('test feature '):\n",
    "    # 计算动态特征\n",
    "    for idx, slice in enumerate(test_vocs):  \n",
    "        ps = [g for _, g in slice.groupby('phone_no_m')]\n",
    "        net = test_nets[idx]\n",
    "        # net: nx.DiGraph\n",
    "        for p in ps:  # each person in this slice\n",
    "            p_dict=p.to_dict(orient='list')\n",
    "            id = p['phone_no_m'].iloc[0]\n",
    "            if idx == 0:\n",
    "                repeat_rate = 0\n",
    "            else:\n",
    "                pre_week = test_vocs[idx - 1]\n",
    "                pre_week = pre_week.loc[pre_week['phone_no_m'] == id]\n",
    "                repeat_rate = connector_duplicate2(pre_week.to_dict(orient='list'), p_dict)\n",
    "            indegree = net.indegree(id)\n",
    "            outdegree = net.outdegree(id)\n",
    "            neighbor_degree = list()\n",
    "            for neigh in net.getNeighbor(id):\n",
    "                neighbor_degree.append(net.indegree(neigh)+net.outdegree(neigh))\n",
    "            neighbor_degree = np.mean(neighbor_degree)\n",
    "            coefficient = net.getCE(id)\n",
    "            recall_rate = features.recall_rate2(p_dict)\n",
    "            time_dis = [0 for i in range(24)]\n",
    "            for time, count in p['hour'].value_counts(normalize=True).to_dict().items():\n",
    "                time_dis[time] = count\n",
    "            \n",
    "            mean_dur = p['mean_dur'].iloc[0]\n",
    "            var_dur = p['var_dur'].iloc[0]\n",
    "            if idx == 0: test_slice_feature[id] = list()\n",
    "            test_slice_feature[id].append([indegree, outdegree, neighbor_degree, coefficient, recall_rate, repeat_rate, mean_dur,var_dur] + time_dis)\n",
    "            tmp_test_user.discard(id)\n",
    "        for id in list(tmp_test_user):  # persons not in this slice\n",
    "            if idx == 0: test_slice_feature[id] = list()\n",
    "            test_slice_feature[id] .append( [0 for i in range(32)])\n",
    "        tmp_test_user=test_user.copy()\n",
    "    # 计算身份特征\n",
    "    static_voc = test_voc[['phone_no_m', 'energy_dispersion']].drop_duplicates(subset='phone_no_m').set_index(\n",
    "        keys='phone_no_m')\n",
    "    for id in list(test_user):\n",
    "        idcard_cnt = all_user.loc[id, 'idcard_cnt']\n",
    "        ed = static_voc.loc[id, 'energy_dispersion']\n",
    "        test_id_feature[id] = [idcard_cnt, ed]\n",
    "np_feature=[]   \n",
    "np_id_feature=[]\n",
    "labels=[]\n",
    "for id, v in test_slice_feature.items(): \n",
    "    np_feature.append(v)\n",
    "    np_id_feature.append(test_id_feature[id])\n",
    "    labels.append(all_user.loc[id, 'label'])\n",
    "\n",
    "np_feature = np.array(np_feature).astype(np.float)\n",
    "np_id_feature = np.array(np_id_feature).astype(np.float)\n",
    "labels = np.array(labels)\n",
    "# test_n=int(len(np_feature)/4)*3\n",
    "np_feature[:, :,[0,1, 2, 3, 6,7]] = normalize(np_feature[:, :,[0,1, 2, 3, 6, 7]])\n",
    "\n",
    "np_id_feature[:,[0]]=normalize(np_id_feature[:,[0]])\n",
    "\n",
    "np.save(arr=np_feature, file=data_path + f'data_after/mymodel/test_x.npy')\n",
    "np.save(arr=np_id_feature, file=data_path + 'data_after/mymodel/test_x_id.npy')\n",
    "np.save(arr=labels, file=data_path + f'data_after/mymodel/test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.load('D:\\\\pycharmProjs\\\\sichuan_data\\\\data_after\\\\mymodel\\\\train_x.npy')\n",
    "test_x=np.load('D:\\\\pycharmProjs\\\\sichuan_data\\\\data_after\\\\mymodel\\\\test_x.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.nan_to_num(train_x,)\n",
    "test_x=np.nan_to_num(test_x,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('D:\\\\pycharmProjs\\\\sichuan_data\\\\data_after\\\\mymodel\\\\train_x.npy',train_x)\n",
    "np.save('D:\\\\pycharmProjs\\\\sichuan_data\\\\data_after\\\\mymodel\\\\test_x.npy',test_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fraud')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "33c62cdab38c2d10cdd558d086fcf6c94cacd04113ccd20163b0963870477146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
